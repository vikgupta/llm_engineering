{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from sympy import randprime, prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809daaf7-ac15-4748-bc22-a6dfdc4e6263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50f376c-3a3e-4364-8b0c-191d20bcf197",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an online tutoring platform. \"\n",
    "system_message += \"You specialise in Maths and Science concepts for students in grades first to tenth. \"\n",
    "system_message += \"Give courteous answers to the academic questions, with a hint of playfulness, no more than 2 sentences. \"\n",
    "system_message += \"Don't entertain non academic questions and respond in a subtle tone to check online resources. \"\n",
    "system_message += \"If possible, provide the references to online resources. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039c114b-1da9-492f-a5bf-37886830cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return random prime number between 1 to upper_range\n",
    "def rand_prime(upper_range):\n",
    "    return randprime(1,upper_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1621eb19-e461-4de6-aea8-5abeb80a530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return nth prime\n",
    "def nth_prime(n):\n",
    "    return prime(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96d4a9e-0fe8-44a1-8790-43a3880a7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary structure for defining the functions to be used as tool\n",
    "\n",
    "rand_prime_function = {\n",
    "    \"name\": \"rand_prime\",\n",
    "    \"description\": \"Returns a random prime number between 1 and an upper range provided by user. If user asks for a prime number greater than 10000 or less than 1, ask to check back in later.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"upper_range\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The upper range for which the user is interested in finding a random prime number\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"upper_range\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "nth_prime_function = {\n",
    "    \"name\": \"nth_prime\",\n",
    "    \"description\": \"Returns nth prime number with 2 being used as the first prime number. If user asks for a 101th or further prime number, ask to check back in later.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"n\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The nth prime number user is interested in\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"n\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5e9dac-90f4-435e-91f4-ff3bdb89b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": rand_prime_function},\n",
    "    {\"type\": \"function\", \"function\": nth_prime_function}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8340bb3-c4ed-42c9-9382-ab3b882effbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call_rand_prime(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    upper_range = arguments.get(\"upper_range\")\n",
    "    result = rand_prime(upper_range)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"result\": result}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dde65e59-c110-4338-8426-20ea451461de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call_nth_prime(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    n = arguments.get(\"n\")\n",
    "    result = nth_prime(n)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"result\": result}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12f203e4-061a-40d1-8493-f139d1db2ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7893\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7893/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function looks rather simpler than the one from my video, because we're taking advantage of the latest Gradio updates\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        tool_call = message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        result = {}\n",
    "        if function_name == \"rand_prime\":\n",
    "            result = handle_tool_call_rand_prime(message)\n",
    "        elif function_name == \"nth_prime\":\n",
    "            result = handle_tool_call_nth_prime(message)\n",
    "        messages.append(message)\n",
    "        messages.append(result)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126f5d3-3f33-4d97-ac3a-c43cfbc1b203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
