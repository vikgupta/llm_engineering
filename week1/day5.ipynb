{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2024/11/13/llm-engineering-resources/',\n",
       " 'https://edwarddonner.com/2024/11/13/llm-engineering-resources/',\n",
       " 'https://edwarddonner.com/2024/10/16/from-software-engineer-to-ai-data-scientist-resources/',\n",
       " 'https://edwarddonner.com/2024/10/16/from-software-engineer-to-ai-data-scientist-resources/',\n",
       " 'https://edwarddonner.com/2024/08/06/outsmart/',\n",
       " 'https://edwarddonner.com/2024/08/06/outsmart/',\n",
       " 'https://edwarddonner.com/2024/06/26/choosing-the-right-llm-resources/',\n",
       " 'https://edwarddonner.com/2024/06/26/choosing-the-right-llm-resources/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "ed.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages. Ignore the news link.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages. Ignore the news link.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2024/11/13/llm-engineering-resources/\n",
      "https://edwarddonner.com/2024/11/13/llm-engineering-resources/\n",
      "https://edwarddonner.com/2024/10/16/from-software-engineer-to-ai-data-scientist-resources/\n",
      "https://edwarddonner.com/2024/10/16/from-software-engineer-to-ai-data-scientist-resources/\n",
      "https://edwarddonner.com/2024/08/06/outsmart/\n",
      "https://edwarddonner.com/2024/08/06/outsmart/\n",
      "https://edwarddonner.com/2024/06/26/choosing-the-right-llm-resources/\n",
      "https://edwarddonner.com/2024/06/26/choosing-the-right-llm-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    # response = openai.chat.completions.create(\n",
    "    #     model=MODEL,\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "    #         {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "    #   ],\n",
    "    #     response_format={\"type\": \"json_object\"}\n",
    "    # )\n",
    "    response = ollama.chat(model=\"llama3.2\", messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ]\n",
    "    )\n",
    "    # result = response.choices[0].message.content\n",
    "    result = response['message']['content']\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/claude',\n",
       " '/team',\n",
       " '/enterprise',\n",
       " '/api',\n",
       " '/pricing',\n",
       " '/research',\n",
       " '/company',\n",
       " '/careers',\n",
       " '/news',\n",
       " 'https://www.anthropic.com/research#entry:8@1:url',\n",
       " 'https://www.anthropic.com/claude',\n",
       " 'https://claude.ai/',\n",
       " '/api',\n",
       " '/news/3-5-models-and-computer-use',\n",
       " '/claude/sonnet',\n",
       " '/claude/haiku',\n",
       " '/news/claude-for-enterprise',\n",
       " '/research/constitutional-ai-harmlessness-from-ai-feedback',\n",
       " '/news/core-views-on-ai-safety',\n",
       " '/jobs',\n",
       " '/',\n",
       " '/claude',\n",
       " '/api',\n",
       " '/team',\n",
       " '/pricing',\n",
       " '/research',\n",
       " '/company',\n",
       " '/customers',\n",
       " '/news',\n",
       " '/careers',\n",
       " 'mailto:press@anthropic.com',\n",
       " 'https://support.anthropic.com/',\n",
       " 'https://status.anthropic.com/',\n",
       " '/supported-countries',\n",
       " 'https://twitter.com/AnthropicAI',\n",
       " 'https://www.linkedin.com/company/anthropicresearch',\n",
       " 'https://www.youtube.com/@anthropic-ai',\n",
       " '/legal/consumer-terms',\n",
       " '/legal/commercial-terms',\n",
       " '/legal/privacy',\n",
       " '/legal/aup',\n",
       " '/responsible-disclosure-policy',\n",
       " 'https://trust.anthropic.com/']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anthropic = Website(\"https://anthropic.com\")\n",
    "anthropic.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'company page', 'url': 'https://www.anthropic.com'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/careers'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research#entry:8@1:url'},\n",
       "  {'type': 'claude webpage', 'url': 'https://www.anthropic.com/claude'},\n",
       "  {'type': 'claude website', 'url': 'https://claude.ai/'},\n",
       "  {'type': 'customers page', 'url': 'https://www.anthropic.com/customers'},\n",
       "  {'type': 'pricing page', 'url': 'https://www.anthropic.com/pricing'},\n",
       "  {'type': 'supported countries page',\n",
       "   'url': 'https://www.anthropic.com/supported-countries'}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    # print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landing page:\n",
      "Webpage Title:\n",
      "Home \\ Anthropic\n",
      "Webpage Contents:\n",
      "Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "AI\n",
      "research\n",
      "and\n",
      "products\n",
      "that put safety at the frontier\n",
      "Claude.ai\n",
      "Meet Claude 3.5 Sonnet\n",
      "Claude 3.5 Sonnet, our most intelligent AI model, is now available.\n",
      "Talk to Claude\n",
      "API\n",
      "Build with Claude\n",
      "Start using Claude to drive efficiency and create new revenue streams.\n",
      "Learn more\n",
      "Announcements\n",
      "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku\n",
      "Oct 22, 2024\n",
      "Model updates\n",
      "3.5 Sonnet\n",
      "3.5 Haiku\n",
      "Our Work\n",
      "Product\n",
      "Claude for Enterprise\n",
      "Sep 4, 2024\n",
      "Alignment\n",
      "·\n",
      "Research\n",
      "Constitutional AI: Harmlessness from AI Feedback\n",
      "Dec 15, 2022\n",
      "Announcements\n",
      "Core Views on AI Safety: When, Why, What, and How\n",
      "Mar 8, 2023\n",
      "Work with Anthropic\n",
      "Anthropic is an AI safety and research company based in San Francisco. Our interdisciplinary team has experience across ML, physics, policy, and product. Together, we generate research and create reliable, beneficial AI systems.\n",
      "See open roles\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2024 Anthropic PBC\n",
      "\n",
      "\n",
      "\n",
      "About page\n",
      "Webpage Title:\n",
      "Company \\ Anthropic\n",
      "Webpage Contents:\n",
      "Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Making AI systems\n",
      "you can rely on\n",
      "Anthropic is an AI safety and research company. We build reliable, interpretable, and steerable AI systems.\n",
      "Join us\n",
      "Our Purpose\n",
      "We believe AI will have a vast impact on the world. Anthropic is dedicated to building systems that people can rely on and generating research about the opportunities and risks of AI.\n",
      "We Build Safer Systems\n",
      "We aim to build frontier AI systems that are reliable, interpretable, and steerable. We conduct frontier research, develop and apply a variety of safety techniques, and deploy the resulting systems via a set of partnerships and products.\n",
      "Safety Is a Science\n",
      "We treat AI safety as a systematic science, conducting research, applying it to our products, feeding those insights back into our research, and regularly sharing what we learn with the world along the way.\n",
      "Interdisciplinary\n",
      "Anthropic is a collaborative team of researchers, engineers, policy experts, business leaders and operators, who bring our experience from many different domains to our work.\n",
      "AI Companies are One Piece of a Big Puzzle\n",
      "AI has the potential to fundamentally change how the world works. We view ourselves as just one piece of this evolving puzzle. We collaborate with civil society, government, academia, nonprofits and industry to promote safety industry-wide.\n",
      "The Team\n",
      "We’re a team of researchers, engineers, policy experts and operational leaders, with experience spanning a variety of disciplines, all working together to build reliable and understandable AI systems.\n",
      "Research\n",
      "We conduct frontier AI research across a variety of modalities, and explore novel and emerging safety research areas from interpretability to RL from human feedback to policy and societal impacts analysis.\n",
      "Policy\n",
      "We think about the impacts of our work and strive to communicate what we’re seeing at the frontier to policymakers and civil society in the US and abroad to help promote safe and reliable AI.\n",
      "Product\n",
      "We translate our research into tangible, practical tools like Claude that benefit businesses, nonprofits and civil society groups and their clients and people around the globe.\n",
      "Operations\n",
      "Our people, finance, legal, and recruiting teams are the human engines that make Anthropic go. We’ve had previous careers at NASA, startups, and the armed forces and our diverse experiences help make Anthropic a great place to work (and we love plants!).\n",
      "Our Values\n",
      "01\n",
      "Here for the mission\n",
      "Anthropic exists for our mission: to ensure transformative AI helps people and society flourish. Progress this decade may be rapid, and we expect increasingly capable systems to pose novel challenges. We pursue our mission by building frontier systems, studying their behaviors, working to responsibly deploy them, and regularly sharing our safety insights. We collaborate with other projects and stakeholders seeking a similar outcome.\n",
      "02\n",
      "Unusually high trust\n",
      "Our company is an unusually high trust environment: we assume good faith, disagree kindly, and prioritize honesty. We expect emotional maturity and intellectual openness. At its best, our trust enables us to make better decisions as an organization than any one of us could as individuals.\n",
      "03\n",
      "One big team\n",
      "Collaboration is central to our work, culture, and value proposition. While we have many teams at Anthropic, we feel the broader sense in which we are all on the same team working together towards the mission. Leadership sets the strategy, with broad input from everyone, and trusts each piece of the organization to pursue these goals in their unique style. Individuals commonly contribute to work across many different areas.\n",
      "04\n",
      "Do the simple thing that works\n",
      "We celebrate trying the simple thing before the clever, novel thing. We embrace pragmatism - sensible, practical approaches that acknowledge tradeoffs. We love empiricism - finding out what actually works by trying it - and apply this to our research, our engineering and our collaboration. We aim to be open about what we understand and what we don’t.\n",
      "Governance\n",
      "Anthropic is a Public Benefit Corporation, whose purpose is the responsible development and maintenance of advanced AI for the long-term benefit of humanity. Our Board of Directors is elected by stockholders and our Long-Term Benefit Trust, as explained\n",
      "here.\n",
      "Current members of the Board and the Long-Term Benefit Trust (LTBT) are listed below.\n",
      "Anthropic Board of Directors\n",
      "Dario Amodei, Daniela Amodei, Yasmin Razavi, and Jay Kreps.\n",
      "LTBT Trustees\n",
      "Neil Buddy Shah, Kanika Bahl, and Zach Robinson.\n",
      "Company News\n",
      "See All\n",
      "Announcements\n",
      "Introducing the Model Context Protocol\n",
      "Nov 25, 2024\n",
      "Announcements\n",
      "Powering the next generation of AI development with AWS\n",
      "Nov 22, 2024\n",
      "Announcements\n",
      "Claude 3.5 Sonnet on GitHub Copilot\n",
      "Oct 29, 2024\n",
      "Want to help us build the future of safe AI?\n",
      "Join us\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2024 Anthropic PBC\n",
      "\n",
      "\n",
      "\n",
      "Careers/Jobs page\n",
      "Webpage Title:\n",
      "Careers \\ Anthropic\n",
      "Webpage Contents:\n",
      "Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Join the team\n",
      "making AI safe\n",
      "We’re a public benefit corporation headquartered in San Francisco. Our team’s experience spans a variety of backgrounds and disciplines, from physics and machine learning to public policy and business. We work as a cohesive team that collectively forecasts the impact and tractability of research ideas in advancing our mission.\n",
      "See open roles\n",
      "What We Offer\n",
      "Health & Wellness\n",
      "At Anthropic, we believe that supporting our employees is crucial to our collective success and wellbeing. That's why we offer a range of benefits to best support you and your family, now and in the future.\n",
      "Comprehensive health, dental, and vision insurance for you and your dependents\n",
      "Inclusive fertility benefits via Carrot Fertility\n",
      "22 weeks of paid parental leave\n",
      "Flexible paid time off and absence policies\n",
      "Generous mental health support for you and your dependents\n",
      "Compensation & Support\n",
      "Our goal is to foster an environment where you can thrive professionally while feeling confident that you and your loved ones are taken care of.\n",
      "Competitive salary and equity packages\n",
      "Optional equity donation matching at a 1:1 ratio, up to 25% of your equity grant\n",
      "Robust retirement plans and salary sacrifice programs with market competitive matching\n",
      "Life and income protection plans\n",
      "Additional Benefits\n",
      "$500/month flexible wellness and time saver stipend\n",
      "Commuter benefits\n",
      "Annual education stipend\n",
      "Home office stipends\n",
      "Relocation support for those moving for Anthropic\n",
      "Daily meals and snacks in the office\n",
      "How We Hire\n",
      "The interview process at Anthropic varies based on role and candidate, but our standard process looks like this:\n",
      "Step 1\n",
      "Resume\n",
      "Submit your resume via our website.\n",
      "Step 2\n",
      "Exploratory chat\n",
      "You’ll have a chat with one of our staff to discuss your career interests and relevant experience, and learn more about Anthropic.\n",
      "Step 3\n",
      "Skills Assessment\n",
      "For technical roles, you’ll have a one-hour technical screening interview.\n",
      "For operations or policy roles, you’ll get a take-home assignment. These typically involve writing responses to several role-relevant questions; they may occasionally require some outside research. Assignments usually take between 2-5 hours, depending on the role.\n",
      "We include this to minimize bias and make well-informed hiring decisions. We think seeing a candidate’s work helps us assess how they might actually perform on the job; similarly, the assignment gives candidates a better idea of what their work at Anthropic might entail. If a candidate likes working through their take-home, that is one indicator that they would enjoy taking on the role, and vice versa.\n",
      "We recognize that completing work assignments requires time and effort, and that they are not perfectly reflective of the role’s work. Nonetheless, we think that work tests are a useful complement to interviews and reference checks.\n",
      "Step 4\n",
      "Team Screen\n",
      "You'll have a conversation with either the Hiring Manager or a member of your potential team.\n",
      "Step 5\n",
      "Interview Panel\n",
      "For technical roles, you’ll have 3-4 more one-hour technical interviews, plus a culture interview.\n",
      "For operations or policy roles, you’ll have 3-5 hours of interviews, including a culture interview.\n",
      "Step 6\n",
      "Final Checks\n",
      "We’ll ask for some references, and have you chat with our leadership.\n",
      "Step 7\n",
      "Offer\n",
      "We’ll make you an offer!\n",
      "Technical Interviews\n",
      "The novel challenges we think about at Anthropic demand diverse expertise and perspectives. Our interview process is designed to identify thoughtful candidates who bring unique strengths to our multidisciplinary team. If you think this may describe you, we’d love to hear from you regardless of your background or experience.\n",
      "One of the most common questions we get is about whether it is worth applying to work at Anthropic if you have not worked on modern machine learning systems in the past. Yes! For some roles, ML experience is expected, but many technical staff have arrived at Anthropic with no machine learning experience. If you aren’t sure about the ML experience needed for your role, ask your recruiter.\n",
      "We use shared environments like Colab and Replit for our programming-focused interviews. We’ll be very interested in how you think through each problem and analyze the tradeoffs between possible approaches, and we’ll also expect you to write, run, and debug your solutions. You’ll be allowed to look things up in documentation or on the web, just like you usually can (which is why we’ll ask you to share your screen throughout each interview); but it’s still important to be familiar with basic syntax, standard libraries, and common idioms in the language you’re interviewing in, so that looking things up doesn’t consume too much time. Your interview process will also include non-technical questions about your experience and what motivates you, and, of course, you’ll have time to ask us about Anthropic! We can’t wait to meet you.\n",
      "Other Things\n",
      "Engineers here do lots of research, and researchers do lots of engineering\n",
      "While there’s historically been a division between engineering and research in machine learning, we think that boundary has dissolved with the advent of large models. The distribution of candidates we interview is strongly bimodal in both engineering and research experience however, and we have necessarily tailored our interview structure to that.\n",
      "If you’ve an engineering background, please apply as an engineer. You’ll perform much better in the interviews, and if you join you’ll have as much input to Anthropic’s direction and interests as anyone else.\n",
      "As evidence towards this: all of our papers have engineers as authors, and often as first author. Research and engineering hires all share a single title - ‘Member of Technical Staff’.\n",
      "We value direct evidence of ability\n",
      "If you’ve done interesting independent research, written an insightful blog post, or made substantial contributions to open-source software, put that at the top of your resume!\n",
      "Feedback\n",
      "We do not provide feedback on resumes or interviews.\n",
      "Visas\n",
      "Anthropic sponsors visas! We aren't able to sponsor them for every role and every candidate; operations roles are especially difficult to support. But if we make you an offer, we will make every effort to get you into the United States, and we retain an immigration lawyer to help with this.\n",
      "Green cards\n",
      "Once you’re eligible, we’re also keen to sponsor green cards!\n",
      "We do not require PhDs, degrees, or previous ML experience\n",
      "About half of Anthropic technical staff have a PhD of some sort; about half had prior experience in ML. We have several brilliant colleagues who never went to college.\n",
      "Remote interviewing\n",
      "All our interviews are conducted over Google Meet. We prefer PST office hours, but we can be flexible if that’s difficult for you.\n",
      "Re-applying\n",
      "Similarly, if interviews don’t work out this time, you’re welcome to re-apply after 12 months, and earlier if something materially changes about your experience or skills.\n",
      "Remote work\n",
      "Anthropic staff all come to the office regularly. Most staff live in the Bay Area, though a few live further away and come in for one week a month. We also understand that moving can take time, so as a transitional phase some folks start while fully remote.\n",
      "Offer timing\n",
      "If we make an offer, we’re happy to give you time to think about it and finish up any other interview processes you’re going through.\n",
      "Internships\n",
      "We do not offer internships.\n",
      "Candidate Privacy Policy\n",
      "US Candidate Privacy Policy\n",
      "UK Employee and Candidate Privacy Policy\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2024 Anthropic PBC\n",
      "\n",
      "\n",
      "\n",
      "Research page\n",
      "Webpage Title:\n",
      "Research \\ Anthropic\n",
      "Webpage Contents:\n",
      "Claude\n",
      "Overview\n",
      "Team\n",
      "Enterprise\n",
      "API\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Careers\n",
      "News\n",
      "Researching\n",
      "at the frontier\n",
      "At Anthropic, we develop large-scale AI systems, and our research teams help us to create safer, steerable, and more reliable models.\n",
      "See open roles\n",
      "Claude\n",
      "API\n",
      "Team\n",
      "Pricing\n",
      "Research\n",
      "Company\n",
      "Customers\n",
      "News\n",
      "Careers\n",
      "Press Inquiries\n",
      "Support\n",
      "Status\n",
      "Availability\n",
      "Twitter\n",
      "LinkedIn\n",
      "YouTube\n",
      "Terms of Service – Consumer\n",
      "Terms of Service – Commercial\n",
      "Privacy Policy\n",
      "Usage Policy\n",
      "Responsible Disclosure Policy\n",
      "Compliance\n",
      "Privacy Choices\n",
      "© 2024 Anthropic PBC\n",
      "\n",
      "\n",
      "\n",
      "Trust page\n",
      "Webpage Title:\n",
      "Trust Center\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Twitter page\n",
      "Webpage Title:\n",
      "x.com\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn page\n",
      "Webpage Title:\n",
      "No title found\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://anthropic.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:20_000] # Truncate if more than 20,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are looking at a company called: Anthropic\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHome \\\\ Anthropic\\nWebpage Contents:\\nClaude\\nOverview\\nTeam\\nEnterprise\\nAPI\\nPricing\\nResearch\\nCompany\\nCareers\\nNews\\nAI\\nresearch\\nand\\nproducts\\nthat put safety at the frontier\\nClaude.ai\\nMeet Claude 3.5 Sonnet\\nClaude 3.5 Sonnet, our most intelligent AI model, is now available.\\nTalk to Claude\\nAPI\\nBuild with Claude\\nStart using Claude to drive efficiency and create new revenue streams.\\nLearn more\\nAnnouncements\\nIntroducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku\\nOct 22, 2024\\nModel updates\\n3.5 Sonnet\\n3.5 Haiku\\nOur Work\\nProduct\\nClaude for Enterprise\\nSep 4, 2024\\nAlignment\\n·\\nResearch\\nConstitutional AI: Harmlessness from AI Feedback\\nDec 15, 2022\\nAnnouncements\\nCore Views on AI Safety: When, Why, What, and How\\nMar 8, 2023\\nWork with Anthropic\\nAnthropic is an AI safety and research company based in San Francisco. Our interdisciplinary team has experience across ML, physics, policy, and product. Together, we generate research and create reliable, beneficial AI systems.\\nSee open roles\\nClaude\\nAPI\\nTeam\\nPricing\\nResearch\\nCompany\\nCustomers\\nNews\\nCareers\\nPress Inquiries\\nSupport\\nStatus\\nAvailability\\nTwitter\\nLinkedIn\\nYouTube\\nTerms of Service – Consumer\\nTerms of Service – Commercial\\nPrivacy Policy\\nUsage Policy\\nResponsible Disclosure Policy\\nCompliance\\nPrivacy Choices\\n© 2024 Anthropic PBC\\n\\n\\n\\ncompany page\\nWebpage Title:\\nHome \\\\ Anthropic\\nWebpage Contents:\\nClaude\\nOverview\\nTeam\\nEnterprise\\nAPI\\nPricing\\nResearch\\nCompany\\nCareers\\nNews\\nAI\\nresearch\\nand\\nproducts\\nthat put safety at the frontier\\nClaude.ai\\nMeet Claude 3.5 Sonnet\\nClaude 3.5 Sonnet, our most intelligent AI model, is now available.\\nTalk to Claude\\nAPI\\nBuild with Claude\\nStart using Claude to drive efficiency and create new revenue streams.\\nLearn more\\nAnnouncements\\nIntroducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku\\nOct 22, 2024\\nModel updates\\n3.5 Sonnet\\n3.5 Haiku\\nOur Work\\nProduct\\nClaude for Enterprise\\nSep 4, 2024\\nAlignment\\n·\\nResearch\\nConstitutional AI: Harmlessness from AI Feedback\\nDec 15, 2022\\nAnnouncements\\nCore Views on AI Safety: When, Why, What, and How\\nMar 8, 2023\\nWork with Anthropic\\nAnthropic is an AI safety and research company based in San Francisco. Our interdisciplinary team has experience across ML, physics, policy, and product. Together, we generate research and create reliable, beneficial AI systems.\\nSee open roles\\nClaude\\nAPI\\nTeam\\nPricing\\nResearch\\nCompany\\nCustomers\\nNews\\nCareers\\nPress Inquiries\\nSupport\\nStatus\\nAvailability\\nTwitter\\nLinkedIn\\nYouTube\\nTerms of Service – Consumer\\nTerms of Service – Commercial\\nPrivacy Policy\\nUsage Policy\\nResponsible Disclosure Policy\\nCompliance\\nPrivacy Choices\\n© 2024 Anthropic PBC\\n\\n\\n\\ncareers page\\nWebpage Title:\\nCareers \\\\ Anthropic\\nWebpage Contents:\\nClaude\\nOverview\\nTeam\\nEnterprise\\nAPI\\nPricing\\nResearch\\nCompany\\nCareers\\nNews\\nJoin the team\\nmaking AI safe\\nWe’re a public benefit corporation headquartered in San Francisco. Our team’s experience spans a variety of backgrounds and disciplines, from physics and machine learning to public policy and business. We work as a cohesive team that collectively forecasts the impact and tractability of research ideas in advancing our mission.\\nSee open roles\\nWhat We Offer\\nHealth & Wellness\\nAt Anthropic, we believe that supporting our employees is crucial to our collective success and wellbeing. That's why we offer a range of benefits to best support you and your family, now and in the future.\\nComprehensive health, dental, and vision insurance for you and your dependents\\nInclusive fertility benefits via Carrot Fertility\\n22 weeks of paid parental leave\\nFlexible paid time off and absence policies\\nGenerous mental health support for you and your dependents\\nCompensation & Support\\nOur goal is to foster an environment where you can thrive professionally while feeling confident that you and your loved ones are taken care of.\\nCompetitive salary and equity packages\\nOptional equity donation matching at a 1:1 ratio, up to 25% of your equity grant\\nRobust retirement plans and salary sacrifice programs with market competitive matching\\nLife and income protection plans\\nAdditional Benefits\\n$500/month flexible wellness and time saver stipend\\nCommuter benefits\\nAnnual education stipend\\nHome office stipends\\nRelocation support for those moving for Anthropic\\nDaily meals and snacks in the office\\nHow We Hire\\nThe interview process at Anthropic varies based on role and candidate, but our standard process looks like this:\\nStep 1\\nResume\\nSubmit your resume via our website.\\nStep 2\\nExploratory chat\\nYou’ll have a chat with one of our staff to discuss your career interests and relevant experience, and learn more about Anthropic.\\nStep 3\\nSkills Assessment\\nFor technical roles, you’ll have a one-hour technical screening interview.\\nFor operations or policy roles, you’ll get a take-home assignment. These typically involve writing responses to several role-relevant questions; they may occasionally require some outside research. Assignments usually take between 2-5 hours, depending on the role.\\nWe include this to minimize bias and make well-informed hiring decisions. We think seeing a candidate’s work helps us assess how they might actually perform on the job; similarly, the assignment gives candidates a better idea of what their work at Anthropic might entail. If a candidate likes working through their take-home, that is one indicator that they would enjoy taking on the role, and vice versa.\\nWe recognize that completing work assignments requires time and effort, and that they are not perfectly reflective of the role’s work. Nonetheless, we think that work tests are a useful complement to interviews and reference checks.\\nStep 4\\nTeam Screen\\nYou'll have a conversation with either the Hiring Manager or a member of your potential team.\\nStep 5\\nInterview Panel\\nFor technical roles, you’ll have 3-4 more one-hour technical interviews, plus a culture interview.\\nFor operations or policy roles, you’ll have 3-5 hours of interviews, including a culture interview.\\nStep 6\\nFinal Checks\\nWe’ll ask for some references, and have you chat with our leadership.\\nStep 7\\nOffer\\nWe’ll make you an offer!\\nTechnical Interviews\\nThe novel challenges we think about at Anthropic demand diverse expertise and perspectives. Our interview process is designed to identify thoughtful candidates who bring unique strengths to our multidisciplinary team. If you think this may describe you, we’d love to hear from you regardless of your background or experience.\\nOne of the most common questions we get is about whether it is worth applying to work at Anthropic if you have not worked on modern machine learning systems in the past. Yes! For some roles, ML experience is expected, but many technical staff have arrived at Anthropic with no machine learning experience. If you aren’t sure about the ML experience needed for your role, ask your recruiter.\\nWe use shared environments like Colab and Replit for our programming-focused interviews. We’ll be very interested in how you think through each problem and analyze the tradeoffs between possible approaches, and we’ll also expect you to write, run, and debug your solutions. You’ll be allowed to look things up in documentation or on the web, just like you usually can (which is why we’ll ask you to share your screen throughout each interview); but it’s still important to be familiar with basic syntax, standard libraries, and common idioms in the language you’re interviewing in, so that looking things up doesn’t consume too much time. Your interview process will also include non-technical questions about your experience and what motivates you, and, of course, you’ll have time to ask us about Anthropic! We can’t wait to meet you.\\nOther Things\\nEngineers here do lots of research, and researchers do lots of engineering\\nWhile there’s historically been a division between engineering and research in machine learning, we think that boundary has dissolved with the advent of large models. The distribution of candidates we interview is strongly bimodal in both engineering and research experience however, and we have necessarily tailored our interview structure to that.\\nIf you’ve an engineering background, please apply as an engineer. You’ll perform much better in the interviews, and if you join you’ll have as much input to Anthropic’s direction and interests as anyone else.\\nAs evidence towards this: all of our papers have engineers as authors, and often as first author. Research and engineering hires all share a single title - ‘Member of Technical Staff’.\\nWe value direct evidence of ability\\nIf you’ve done interesting independent research, written an insightful blog post, or made substantial contributions to open-source software, put that at the top of your resume!\\nFeedback\\nWe do not provide feedback on resumes or interviews.\\nVisas\\nAnthropic sponsors visas! We aren't able to sponsor them for every role and every candidate; operations roles are especially difficult to support. But if we make you an offer, we will make every effort to get you into the United States, and we retain an immigration lawyer to help with this.\\nGreen cards\\nOnce you’re eligible, we’re also keen to sponsor green cards!\\nWe do not require PhDs, degrees, or previous ML experience\\nAbout half of Anthropic technical staff have a PhD of some sort; about half had prior experience in ML. We have several brilliant colleagues who never went to college.\\nRemote interviewing\\nAll our interviews are conducted over Google Meet. We prefer PST office hours, but we can be flexible if that’s difficult for you.\\nRe-applying\\nSimilarly, if interviews don’t work out this time, you’re welcome to re-apply after 12 months, and earlier if something materially changes about your experience or skills.\\nRemote work\\nAnthropic staff all come to the office regularly. Most staff live in the Bay Area, though a few live further away and come in for one week a month. We also understand that moving can take time, so as a transitional phase some folks start while fully remote.\\nOffer timing\\nIf we make an offer, we’re happy to give you time to think about it and finish up any other interview processes you’re going through.\\nInternships\\nWe do not offer internships.\\nCandidate Privacy Policy\\nUS Candidate Privacy Policy\\nUK Employee and Candidate Privacy Policy\\nClaude\\nAPI\\nTeam\\nPricing\\nResearch\\nCompany\\nCustomers\\nNews\\nCareers\\nPress Inquiries\\nSupport\\nStatus\\nAvailability\\nTwitter\\nLinkedIn\\nYouTube\\nTerms of Service – Consumer\\nTerms of Service – Commercial\\nPrivacy Policy\\nUsage Policy\\nResponsible Disclosure Policy\\nCompliance\\nPrivacy Choices\\n© 2024 Anthropic PBC\\n\\n\\n\\nnews link\\nWebpage Title:\\nNewsroom \\\\ Anthropic\\nWebpage Contents:\\nClaude\\nOverview\\nTeam\\nEnterprise\\nAPI\\nPricing\\nResearch\\nCompany\\nCareers\\nNews\\nNewsroom\\nFeatured\\nPowering the next generation of AI development with AWS\\nPress inquiries\\npress@anthropic.com\\nNon-media inquiries\\nsupport.anthropic.com\\nMedia assets\\nDownload press kit\\nFollow Anthropic\\nFeatured\\nAnnouncing our updated Responsible Scaling Policy\\nFeatured\\nDeveloping a computer use model\\nNews\\nNo results found.\\nProduct\\nClaude 3.5 Haiku on AWS Trainium2 and model distillation in Amazon Bedrock\\nDec 3, 2024\\nProduct\\nTailor Claude’s responses to your personal style\\nNov 26, 2024\\nAnnouncements\\nIntroducing the Model Context Protocol\\nNov 25, 2024\\nAnnouncements\\nPowering the next generation of AI development with AWS\\nNov 22, 2024\\nProduct\\nImprove your prompts in the developer console\\nNov 14, 2024\\nPolicy\\nThe case for targeted regulation\\nOct 31, 2024\\nProduct\\nRaising the bar on SWE-bench Verified with Claude 3.5 Sonnet\\nOct 30, 2024\\nAnnouncements\\nClaude 3.5 Sonnet on GitHub Copilot\\nOct 29, 2024\\nProduct\\nIntroducing the analysis tool in Claude.ai\\nOct 24, 2024\\nAnnouncements\\n·\\nProduct\\nDeveloping a computer use model\\nOct 22, 2024\\nAnnouncements\\nIntroducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku\\nOct 22, 2024\\nAnnouncements\\nAnnouncing our updated Responsible Scaling Policy\\nOct 15, 2024\\nSocietal Impacts\\nU.S. Elections Readiness\\nOct 8, 2024\\nProduct\\nIntroducing the Message Batches API\\nOct 8, 2024\\nProduct\\n·\\nAnnouncements\\nIntroducing Contextual Retrieval\\nSep 19, 2024\\nProduct\\nWorkspaces in the Anthropic API Console\\nSep 10, 2024\\nProduct\\nClaude for Enterprise\\nSep 4, 2024\\nAnnouncements\\nSalesforce teams up with Anthropic to enhance Einstein capabilities with Claude\\nSep 3, 2024\\nAnnouncements\\nArtifacts are now generally available\\nAug 27, 2024\\nProduct\\nPrompt caching with Claude\\nAug 14, 2024\\nAnnouncements\\nExpanding our model safety bug bounty program\\nAug 8, 2024\\nAnnouncements\\nClaude is now available in Brazil\\nAug 1, 2024\\nAnnouncements\\nAnthropic partners with Menlo Ventures to launch Anthology Fund\\nJul 17, 2024\\nProduct\\nClaude Android app\\nJul 16, 2024\\nProduct\\nFine-tune Claude 3 Haiku in Amazon Bedrock\\nJul 11, 2024\\nProduct\\nEvaluate prompts in the developer console\\nJul 9, 2024\\nAnnouncements\\nA new initiative for developing third-party model evaluations\\nJul 1, 2024\\nAnnouncements\\nExpanding access to Claude for government\\nJun 26, 2024\\nProduct\\nCollaborate with Claude on Projects\\nJun 25, 2024\\nAnnouncements\\nClaude 3.5 Sonnet\\nJun 21, 2024\\nPolicy\\nChallenges in red teaming AI systems\\nJun 12, 2024\\nPolicy\\n·\\nSocietal Impacts\\nTesting and mitigating elections-related risks\\nJun 6, 2024\\nAnnouncements\\nIntroducing Claude to Canada\\nJun 5, 2024\\nProduct\\nClaude can now use tools\\nMay 30, 2024\\nAnnouncements\\nJay Kreps appointed to Anthropic's Board of Directors\\nMay 29, 2024\\nProduct\\nGolden Gate Claude\\nMay 23, 2024\\nAnnouncements\\nKrishna Rao joins Anthropic as Chief Financial Officer\\nMay 21, 2024\\nInterpretability\\nMapping the Mind of a Large Language Model\\nMay 21, 2024\\nProduct\\nGenerate better prompts in the developer console\\nMay 20, 2024\\nPolicy\\nReflections on our Responsible Scaling Policy\\nMay 20, 2024\\nAnnouncements\\nMike Krieger joins Anthropic as Chief Product Officer\\nMay 15, 2024\\nAnnouncements\\nClaude is now available in Europe\\nMay 14, 2024\\nAnnouncements\\nUpdating our Usage Policy\\nMay 10, 2024\\nProduct\\n·\\nAnnouncements\\nIntroducing the Claude Team plan and iOS app\\nMay 1, 2024\\nAnnouncements\\nAligning on child safety principles\\nApr 23, 2024\\nAlignment\\nMany-shot jailbreaking\\nApr 2, 2024\\nPolicy\\nThird-party testing as a key ingredient of AI policy\\nMar 25, 2024\\nAnnouncements\\nAnthropic, AWS, and Accenture team up to build trusted solutions for enterprises\\nMar 20, 2024\\nAnnouncements\\nClaude 3 models on Vertex AI\\nMar 19, 2024\\nAnnouncements\\nClaude 3 Haiku: our fastest model yet\\nMar 13, 2024\\nAnnouncements\\nIntroducing the next generation of Claude\\nMar 4, 2024\\nProduct\\nPrompt engineering for business performance\\nFeb 29, 2024\\nPolicy\\nPreparing for global elections in 2024\\nFeb 16, 2024\\nAnnouncements\\nExpanded legal protections and improvements to our API\\nDec 19, 2023\\nProduct\\nLong context prompting for Claude 2.1\\nDec 6, 2023\\nProduct\\nIntroducing Claude 2.1\\nNov 21, 2023\\nPolicy\\nThoughts on the US Executive Order, G7 Code of Conduct, and Bletchley Park Summit\\nNov 5, 2023\\nPolicy\\nDario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling Policy\\nNov 1, 2023\\nAnnouncements\\nClaude on Amazon Bedrock now available to every AWS customer\\nSep 28, 2023\\nAnnouncements\\nExpanding access to safer AI with Amazon\\nSep 25, 2023\\nProduct\\nPrompt engineering for Claude's long context window\\nSep 23, 2023\\nAnnouncements\\nAnthropic's Responsible Scaling Policy\\nSep 19, 2023\\nAnnouncements\\nThe Long-Term Benefit Trust\\nSep 19, 2023\\nAnnouncements\\nAnthropic partners with BCG\\nSep 14, 2023\\nAnnouncements\\nIntroducing Claude Pro\\nSep 7, 2023\\nProduct\\nClaude 2 on Amazon Bedrock\\nAug 23, 2023\\nAnnouncements\\nSKT Partnership Announcement\\nAug 15, 2023\\nAnnouncements\\nReleasing Claude Instant 1.2\\nAug 9, 2023\\nAnnouncements\\nFrontier Threats Red Teaming for AI Safety\\nJul 26, 2023\\nAnnouncements\\nFrontier Model Security\\nJul 25, 2023\\nAnnouncements\\nClaude 2\\nJul 11, 2023\\nAnnouncements\\nCharting a Path to AI Accountability\\nJun 13, 2023\\nAnnouncements\\nAnthropic Raises $450 Million in Series C Funding to Scale Reliable AI Products\\nMay 23, 2023\\nAnnouncements\\nZoom Partnership and Investment in Anthropic\\nMay 16, 2023\\nAnnouncements\\nIntroducing 100K Context Windows\\nMay 11, 2023\\nAnnouncements\\nClaude’s Constitution\\nMay 9, 2023\\nAnnouncements\\nPartnering with Scale to Bring Generative AI to Enterprises\\nApr 26, 2023\\nAnnouncements\\nAn AI Policy Tool for Today: Ambitiously Invest in NIST\\nApr 20, 2023\\nAnnouncements\\nClaude, now in Slack\\nMar 30, 2023\\nAnnouncements\\nIntroducing Claude\\nMar 14, 2023\\nAnnouncements\\nCore Views on AI Safety: When, Why, What, and How\\nMar 8, 2023\\nAnnouncements\\nAnthropic Partners with Google Cloud\\nFeb 3, 2023\\nAnnouncements\\nAnthropic Raises Series B to Build Steerable, Interpretable, Robust AI Systems\\nApr 29, 2022\\nAnnouncements\\nAnthropic raises $124 million to build more reliable, general AI systems\\nMay 28, 2021\\nClaude\\nAPI\\nTeam\\nPricing\\nResearch\\nCompany\\nCustomers\\nNews\\nCareers\\nPress Inquiries\\nSupport\\nStatus\\nAvailability\\nTwitter\\nLinkedIn\\nYouTube\\nTerms of Service – Consumer\\nTerms of Service – Commercial\\nPrivacy Policy\\nUsage Policy\\nResponsible Disclosure Policy\\nCompliance\\nPrivacy Choices\\n© 2024 Anthropic PBC\\n\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"Anthropic\", \"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    # response = openai.chat.completions.create(\n",
    "    #     model=MODEL,\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": system_prompt},\n",
    "    #         {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "    #       ],\n",
    "    # )\n",
    "    # result = response.choices[0].message.content\n",
    "    stream = ollama.chat(model=\"llama3.2\", messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "      ], stream=True\n",
    "    )\n",
    "    # result = response.choices[0].message.content\n",
    "    result = response['message']['content']\n",
    "    display(Markdown(result))\n",
    "    # response = \"\"\n",
    "    # display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    # for chunk in stream:\n",
    "    #     response += chunk['delta']['content'] or ''\n",
    "    #     response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    #     update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatResponse' object has no attribute 'delta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_brochure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnthropic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://anthropic.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 21\u001b[0m, in \u001b[0;36mcreate_brochure\u001b[0;34m(company_name, url)\u001b[0m\n\u001b[1;32m     19\u001b[0m display_handle \u001b[38;5;241m=\u001b[39m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), display_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m     response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     update_display(Markdown(response), display_id\u001b[38;5;241m=\u001b[39mdisplay_handle\u001b[38;5;241m.\u001b[39mdisplay_id)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/ollama/_types.py:20\u001b[0m, in \u001b[0;36mSubscriptableBaseModel.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 20\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pydantic/main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatResponse' object has no attribute 'delta'"
     ]
    }
   ],
   "source": [
    "create_brochure(\"Anthropic\", \"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstream_brochure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnthropic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://anthropic.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m, in \u001b[0;36mstream_brochure\u001b[0;34m(company_name, url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream_brochure\u001b[39m(company_name, url):\n\u001b[0;32m----> 2\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_brochure_user_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     display_handle \u001b[38;5;241m=\u001b[39m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), display_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "stream_brochure(\"Anthropic\", \"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 2 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de35771-455f-40b5-ba44-7c0a6b7c427a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
