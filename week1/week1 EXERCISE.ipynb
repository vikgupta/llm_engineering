{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ollama\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "system_prompt = \"\"\"\n",
    "You are an AI assistant that helps with a detailed explanation on the technical questions. \n",
    "You specialize in python, machine learning, and artificial intelligence concepts and the responses that you provide helpseven a layman understand \n",
    "what's happening.\n",
    "Respond in markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7fb332-fa21-4b53-83b4-ec1f6725e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up message\n",
    "\n",
    "MESSAGES = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "def ask_assistant():\n",
    "    response = ollama.chat(model=MODEL_LLAMA, messages=MESSAGES)\n",
    "    result = response['message']['content']\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8cc6818-1124-4668-a9e0-233199d1d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Understanding the `yield from` Statement**\n",
       "=============================================\n",
       "\n",
       "The given code snippet utilizes a powerful feature in Python called `yield from`. This is used to delegate iteration over another iterable.\n",
       "\n",
       "**Breaking down the Code**\n",
       "---------------------------\n",
       "\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "Here's what happens when we run this code:\n",
       "\n",
       "1. **List Comprehension**: The `{}` notation is used to create a new list comprehension that filters and processes each item in the `books` collection.\n",
       "2. **Filtering**: `for book in books if book.get(\"author\")` ensures that only books with an author are processed.\n",
       "3. **Dictionary Lookup**: `.get(\"author\")` attempts to retrieve the value associated with the key `\"author\"` from each book dictionary.\n",
       "4. **Yielding Values**: The `yield from` statement is used to yield values from the resulting iterable.\n",
       "\n",
       "**How `yield from` Works**\n",
       "---------------------------\n",
       "\n",
       "When a generator (like a list comprehension) uses `yield from`, it:\n",
       "\n",
       "1. Iterates over the inner iterable (`{book.get(\"author\") for book in books if book.get(\"author\")}`).\n",
       "2. Yields each value directly to the caller without storing them in memory.\n",
       "\n",
       "**Benefits of Using `yield from`**\n",
       "---------------------------------\n",
       "\n",
       "Using `yield from` has several advantages:\n",
       "\n",
       "*   **Memory Efficiency**: It avoids creating intermediate lists or data structures, making it a good choice when working with large datasets.\n",
       "*   **Readability**: The code is more readable because the intent of delegating iteration is clearly expressed.\n",
       "\n",
       "**Example Use Case**\n",
       "--------------------\n",
       "\n",
       "Suppose you have a function that processes books and their authors:\n",
       "\n",
       "```python\n",
       "def process_books(books):\n",
       "    for author in yield from {book.get(\"author\") for book in books if book.get(\"author\")}>\n",
       "        print(f\"Processing author: {author}\")\n",
       "\n",
       "# Example usage:\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"John Doe\"},\n",
       "    {\"title\": \"Book 2\", \"author\": None},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Jane Smith\"}\n",
       "]\n",
       "\n",
       "process_books(books)\n",
       "```\n",
       "\n",
       "In this example, the `yield from` statement allows us to iterate over the authors of all books in a memory-efficient manner."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_assistant()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
